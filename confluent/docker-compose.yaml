---
services:

  broker-1:
    image: confluentinc/cp-kafka:${CONFLUENTINC_VERSION:-7.9.1}
    hostname: broker-1
    container_name: broker-1
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/cp-kafka
    ports:
      - "9092:9092"
      - "7071:7071"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-1:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CONTROLLER_QUORUM_VOTERS:-'1@broker-1:29093,2@broker-2:29093,3@broker-3:29093'} 
      KAFKA_LISTENERS: 'PLAINTEXT://broker-1:29092,CONTROLLER://broker-1:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar:/usr/share/java/confluent-telemetry/confluent-metrics-7.9.1-ce.jar
      KAFKA_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      KAFKA_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      KAFKA_CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_MESSAGE_MAX_BYTES: 51200 #50k em bytes (50 * 1024)
      KAFKA_REPLICA_FETCH_MAX_BYTES: 51200 #50k em bytes (50 * 1024)
      KAFKA_REPLICA_FETCH_MIN_BYTES: 1
      KAFKA_OPTS: "-javaagent:/jmx/jmx_prometheus_javaagent-1.3.0.jar=7071:/jmx/kafka-metrics.yml"
      #KAFKA_LOG_RETENTION_HOURS: 168 # 7 dias
      KAFKA_LOG_RETENTION_MS: 172800000 # 2 dias
      KAFKA_COMPRESSION_TYPE: lz4
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_MIN_INSYNC_REPLICAS: 2
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    healthcheck:
      test: ["CMD-SHELL", "nc -z broker-1 29093 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s # Tempo para o broker iniciar antes de começar os checks
    volumes:
      - ./data/libs/monitoring-interceptors-7.9.1.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
      - ./data/libs/confluent-metrics-7.9.1-ce.jar:/usr/share/java/confluent-telemetry/confluent-metrics-7.9.1-ce.jar
      - broker1-data:/var/lib/kafka/data
      - ./data/libs/jmx:/jmx:ro
    networks:
      - kafka-net

  broker-2:
    image: confluentinc/cp-kafka:${CONFLUENTINC_VERSION:-7.9.1}
    hostname: broker-2
    container_name: broker-2
    depends_on:
      broker-1:
        condition: service_healthy
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/cp-kafka
    ports:
      - "9093:9093"
      - "7072:7072"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-2:29092,PLAINTEXT_HOST://localhost:9093'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CONTROLLER_QUORUM_VOTERS:-'1@broker-1:29093,2@broker-2:29093,3@broker-3:29093'} 
      KAFKA_LISTENERS: 'PLAINTEXT://broker-2:29092,CONTROLLER://broker-2:29093,PLAINTEXT_HOST://0.0.0.0:9093'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar:/usr/share/java/confluent-telemetry/confluent-metrics-7.9.1-ce.jar
      KAFKA_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      KAFKA_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      KAFKA_CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_MESSAGE_MAX_BYTES: 51200 #50k em bytes (50 * 1024)
      KAFKA_REPLICA_FETCH_MAX_BYTES: 51200 #50k em bytes (50 * 1024)
      KAFKA_REPLICA_FETCH_MIN_BYTES: 1
      KAFKA_OPTS: "-javaagent:/jmx/jmx_prometheus_javaagent-1.3.0.jar=7072:/jmx/kafka-metrics.yml"
      #KAFKA_LOG_RETENTION_HOURS: 168 # 7 dias
      KAFKA_LOG_RETENTION_MS: 172800000 # 2 dias
      KAFKA_COMPRESSION_TYPE: lz4
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_MIN_INSYNC_REPLICAS: 2
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    healthcheck:
      test: ["CMD-SHELL", "nc -z broker-2 29093 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s # Tempo para o broker iniciar antes de começar os checks
    volumes:
      - ./data/libs/monitoring-interceptors-7.9.1.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
      - ./data/libs/confluent-metrics-7.9.1-ce.jar:/usr/share/java/confluent-telemetry/confluent-metrics-7.9.1-ce.jar
      - broker2-data:/var/lib/kafka/data
      - ./data/libs/jmx:/jmx:ro
    networks:
      - kafka-net

  broker-3:
    image: confluentinc/cp-kafka:${CONFLUENTINC_VERSION:-7.9.1}
    hostname: broker-3
    container_name: broker-3
    depends_on:
      broker-1:
        condition: service_healthy
      broker-2:
        condition: service_healthy
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/cp-kafka
    ports:
      - "9094:9094"
      - "7073:7073"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-3:29092,PLAINTEXT_HOST://localhost:9094'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CONTROLLER_QUORUM_VOTERS:-'1@broker-1:29093,2@broker-2:29093,3@broker-3:29093'} 
      KAFKA_LISTENERS: 'PLAINTEXT://broker-3:29092,CONTROLLER://broker-3:29093,PLAINTEXT_HOST://0.0.0.0:9094'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar:/usr/share/java/confluent-telemetry/confluent-metrics-7.9.1-ce.jar
      KAFKA_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      KAFKA_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      KAFKA_CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KAFKA_MESSAGE_MAX_BYTES: 51200 #50k em bytes (50 * 1024)
      KAFKA_REPLICA_FETCH_MAX_BYTES: 51200 #50k em bytes (50 * 1024)
      KAFKA_REPLICA_FETCH_MIN_BYTES: 1 
      KAFKA_OPTS: "-javaagent:/jmx/jmx_prometheus_javaagent-1.3.0.jar=7073:/jmx/kafka-metrics.yml" 
      #KAFKA_LOG_RETENTION_HOURS: 168 # 7 dias   
      KAFKA_LOG_RETENTION_MS: 172800000 # 2 dias
      KAFKA_COMPRESSION_TYPE: lz4
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_MIN_INSYNC_REPLICAS: 2
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    volumes:
      - ./data/libs/monitoring-interceptors-7.9.1.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
      - ./data/libs/confluent-metrics-7.9.1-ce.jar:/usr/share/java/confluent-telemetry/confluent-metrics-7.9.1-ce.jar
      - broker3-data:/var/lib/kafka/data
      - ./data/libs/jmx:/jmx:ro
    healthcheck:
      test: ["CMD-SHELL", "nc -z broker-3 29093 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s # Tempo para o broker iniciar antes de começar os checks
    networks:
      - kafka-net

  schema-registry:
    image: confluentinc/cp-schema-registry:${CONFLUENTINC_VERSION:-7.9.1}
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      broker-1:
        condition: service_started
        required: false
      broker-2:
        condition: service_started
        required: false
      broker-3:
        condition: service_started
        required: false
    healthcheck:
      test: ["CMD-SHELL", "nc -z schema-registry 8081 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s # Tempo para o broker iniciar antes de começar os checks
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/cp-schema-registry
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      - kafka-net
  
  schema-registry-init:
    image: curlimages/curl:8.7.1
    restart: "no"
    container_name: schema-registry-init
    hostname: schema-registry-init
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=8.7.1
      - br.dev.robsonalves.service.description=curlimages/curl
    depends_on:
      schema-registry:
        condition: service_healthy
    entrypoint: sh
    command:
      - -c
      - |
        echo -e "⏳ Aguardando Schema Registry...";
        until curl -s http://schema-registry:8081/subjects > /dev/null; do
          sleep 2;
        done;
        echo -e "✅ Schema Registry disponível, configurando compatibilidade...";
        curl -X PUT http://schema-registry:8081/config -H "Content-Type: application/vnd.schemaregistry.v1+json" -d '{"compatibility": "BACKWARD"}';
        echo -e "\n🎉 Compatibilidade definida como BACKWARD.";
    networks:
      - kafka-net

  connect:
    #image: cnfldemos/cp-server-connect-datagen:0.6.4-7.6.0
    #image: confluentinc/cp-server-connect:${CONFLUENTINC_VERSION:-7.9.1}
    build:
      context: .
      dockerfile: Dockerfile.cp-server-connect
    hostname: connect
    container_name: connect
    depends_on:
      broker-1:
        condition: service_started
        required: false
      broker-2:
        condition: service_started
        required: false
      broker-3:
        condition: service_started
        required: false
      schema-registry:
        condition: service_started
        required: false
    ports:
      - "8083:8083"
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=0.6.4-7.6.0
      - br.dev.robsonalves.service.description=cnfldemos/cp-server-connect-datagen
    environment:
      CONNECT_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/data/plugins"
      TZ: "America/Sao_Paulo"
    volumes:
      - ./data:/data
      - ./data/libs/monitoring-interceptors-7.9.1.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
    command:
      - bash
      - -c
      - |
        #echo "Installing Connector"
        #confluent-hub install --no-prompt debezium/debezium-connector-postgresql:2.4.2
        #confluent-hub install --no-prompt debezium/debezium-connector-mysql:2.4.2
        #confluent-hub install --no-prompt neo4j/kafka-connect-neo4j:5.1.11
        #confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:15.0.0
        #confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.8.4
        #confluent-hub install --no-prompt confluentinc/kafka-connect-datagen:latest
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &
        #
        sleep infinity
    networks:
      - kafka-net

  control-center:
    image: confluentinc/cp-enterprise-control-center:${CONFLUENTINC_VERSION:-7.9.1}
    hostname: control-center
    container_name: control-center
    depends_on:
      broker-1:
        condition: service_started
        required: false
      broker-2:
        condition: service_started
        required: false
      broker-3:
        condition: service_started
        required: false
      schema-registry:
        condition: service_started
        required: false
      connect:
        condition: service_started
        required: false
      ksqldb-server:
        condition: service_started
        required: false
    ports:
      - "9021:9021"
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/cp-enterprise-control-center
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: '/connectors'
      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      CONTROL_CENTER_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONTROL_CENTER_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      #CONTROL_CENTER_KAFKA_REST_URL: "http://rest-proxy:8082"
      PORT: 9021
    volumes:
      - ./data/libs/monitoring-interceptors-7.9.1.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
    networks:
      - kafka-net

  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:${CONFLUENTINC_VERSION:-7.9.1}
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      broker-1:
        condition: service_started
        required: false
      broker-2:
        condition: service_started
        required: false
      broker-3:
        condition: service_started
        required: false
      schema-registry:
        condition: service_started
        required: false
      connect:
        condition: service_started
        required: false
    ports:
      - "8088:8088"
    dns:
      - 1.1.1.1
      - 8.8.8.8
      - 127.0.0.1
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/cp-ksqldb-server
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      KSQL_HOST_NAME: ksqldb-server
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-3}
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
      #CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
      KSQL_KSQL_STREAMS_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      KSQL_KSQL_STREAMS_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      KSQL_AUTO_OFFSET_RESET: earliest
      KSQL_KSQL_HIDDEN_TOPICS: '^docker-connect-offsets|^docker-connect-status|^docker-connect-configs|^(default_)?ksql_.*|^ksql-.*|^_.*'
    volumes:
      - ./data/libs/monitoring-interceptors-7.9.1.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
    networks:
      - kafka-net

  ksqldb-cli:
    image: confluentinc/cp-ksqldb-cli:${CONFLUENTINC_VERSION:-7.9.1}
    container_name: ksqldb-cli
    hostname: ksqldb-cli
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/cp-ksqldb-cli
    depends_on:
      ksqldb-server:
        condition: service_started
    entrypoint: /bin/sh
    tty: true
    networks:
      - kafka-net

  ksql-datagen:
    image: confluentinc/ksqldb-examples:7.9.1
    hostname: ksql-datagen
    container_name: ksql-datagen
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/ksqldb-examples
    # depends_on:
    #   - ksqldb-server
    #   - broker-1
    #   - broker-2
    #   - broker-3
    #   - schema-registry
    #   - connect
    command: 
      - bash
      - -c
      - |
        echo "Waiting for Kafka to be ready..."
        cub kafka-ready -b broker-1:29092 1 40
        echo "Waiting for Confluent Schema Registry to be ready..."
        cub sr-ready schema-registry 8081 40
        echo "Waiting a few seconds for topic creation to finish..."
        sleep 11
        tail -f /dev/null
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      STREAMS_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
      STREAMS_SCHEMA_REGISTRY_PORT: 8081
    networks:
      - kafka-net

  rest-proxy:
    image: confluentinc/cp-kafka-rest:${CONFLUENTINC_VERSION:-7.9.1}
    depends_on:
      broker-1:
        condition: service_started
        required: false
      broker-2:
        condition: service_started
        required: false
      broker-3:
        condition: service_started
        required: false
      schema-registry:
        condition: service_started
        required: false
      connect:
        condition: service_started
        required: false
    ports:
      - 8082:8082
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=${CONFLUENTINC_VERSION:-7.9.1}
      - br.dev.robsonalves.service.description=confluentinc/cp-kafka-rest
    hostname: rest-proxy
    container_name: rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      #CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
      KAFKA_REST_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      KAFKA_REST_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
    volumes:
      - ./data/libs/monitoring-interceptors-7.9.1.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.1.jar
    networks:
      - kafka-net

  # redpanda:
  #   image: docker.redpanda.com/redpandadata/console:latest
  #   container_name: redpanda
  #   hostname: redpanda
  #   depends_on:
  #     - broker-1
  #     - broker-2
  #     - broker-3
  #     - schema-registry
  #   ports:
  #     - 9022:8080
  #   labels:
  #     - br.dev.robsonalves.service.group=kafka
  #     - br.dev.robsonalves.service.version=latest
  #     - br.dev.robsonalves.service.description=docker.redpanda.com/redpandadata/console
  #   environment:
  #     KAFKA_BROKERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
  #   networks:
  #     - kafka-net

  redpanda:
    image: docker.redpanda.com/redpandadata/console:latest
    container_name: redpanda
    hostname: redpanda
    depends_on:
      broker-1:
        condition: service_started
        required: false
      broker-2:
        condition: service_started
        required: false
      broker-3:
        condition: service_started
        required: false
      schema-registry:
        condition: service_started
        required: false
      connect:
        condition: service_started
        required: false
    ports:
      - 9022:8080
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=latest
      - br.dev.robsonalves.service.description=docker.redpanda.com/redpandadata/console
    environment:
      KAFKA_BROKERS: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
      CONFIG_FILEPATH: "/tmp/redpanda-console-config.yaml"
      CONSOLE_CONFIG_FILE: |
        # Configure a connection to the Redpanda cluster
        # See https://docs.redpanda.com/current/console/config/connect-to-redpanda/
        kafka:
          brokers: ["broker-1:29092","broker-2:29092","broker-3:29092"]
    volumes:
      - ./data/redpanda:/tmp
    networks:
      - kafka-net

  akhq:
    image: tchiotludo/akhq
    container_name: akhq
    hostname: akhq
    depends_on:
      broker-1:
        condition: service_started
        required: false
      broker-2:
        condition: service_started
        required: false
      broker-3:
        condition: service_started
        required: false
      schema-registry:
        condition: service_started
        required: false
      connect:
        condition: service_started
        required: false
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: ${BOOTSTRAP_SERVERS:-'broker-1:29092,broker-2:29092,broker-3:29092'}
              schema-registry:
                url: "http://schema-registry:8081"
              connect:
                - name: "connect"
                  url: "http://connect:8083"
    ports:
      - 9023:8080
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=latest
      - br.dev.robsonalves.service.description=tchiotludo/akhq
    # depends_on:
    #   - broker-1
    #   - broker-2
    #   - broker-3
    #   - schema-registry
    networks:
      - kafka-net

  postgres-kafka-db:
    image: postgres
    hostname: postgres-kafka-db
    container_name: postgres-kafka-db
    ports:
      - "5432:5432"
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=latest
      - br.dev.robsonalves.service.description=postgres
    # set shared memory limit when using docker compose
    shm_size: 128mb
    # or set shared memory limit when deploy via swarm stack
    #volumes:
    #  - type: tmpfs
    #    target: /dev/shm
    #    tmpfs:
    #      size: 134217728 # 128*2^20 bytes = 128Mb
    environment:
      POSTGRES_PASSWORD: example
    volumes:
      - ./data/postgres:/docker-entrypoint-initdb.d
    networks:
      - kafka-net

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    hostname: prometheus
    ports:
      - 9090:9090
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=latest
      - br.dev.robsonalves.service.description=prom/prometheus
    volumes:
      - "./data/prometheus/:/etc/prometheus/"
    networks:
      - kafka-net

  grafana:
    image: grafana/grafana
    labels:
      - br.dev.robsonalves.service.group=kafka
      - br.dev.robsonalves.service.version=latest
      - br.dev.robsonalves.service.description=grafana/grafana
    container_name: grafana
    hostname: grafana
    ports:
      - 3000:3000
    networks:
      - kafka-net

networks:
  kafka-net:
    driver: bridge

volumes:
  broker1-data:
  broker2-data:
  broker3-data:
